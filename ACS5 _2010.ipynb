{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import csv\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Census(\"4c26aa6ebbaef54a55d3903212eabbb506ade381\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 60000, 75000, \n",
    "           100000, 125000, 150000, 200000,1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_2 = [0, 10000, 15000, 25000, 35000, 50000, 65000, 75000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=['B19013_001E','B19013_001M']\n",
    "for i in range(2,10):\n",
    "    var.append('B19001_00'+str(i)+'E')\n",
    "    var.append('B19001_00'+str(i)+'M')\n",
    "for i in range(10,18):\n",
    "    var.append('B19001_0'+str(i)+'E')\n",
    "    var.append('B19001_0'+str(i)+'M')\n",
    "for i in range(3,10):\n",
    "    var.append('B07010_00'+str(i)+'E')\n",
    "    var.append('B07010_00'+str(i)+'M')\n",
    "for i in range(10,12):\n",
    "    var.append('B07010_0'+str(i)+'E')\n",
    "    var.append('B07010_0'+str(i)+'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the state and insert it as part as the api json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alabama\t        01  AL\n",
    "Alaska\t        02  AK\n",
    "Arizona\t        04  AZ\n",
    "Arkansas\t    05  AR\n",
    "California\t    06  CA\n",
    "Colorado\t    08  CO\n",
    "Connecticut\t    09\tCT\n",
    "Delaware\t    10\tDE\n",
    "D.C.         \t11\tDC\n",
    "Florida\t        12\tFL\n",
    "Georgia\t        13\tGA\n",
    "Hawaii\t        15\tHI\n",
    "Idaho\t        16\tID\n",
    "Illinois\t    17\tIL\n",
    "Indiana\t        18\tIN\n",
    "Iowa\t        19\tIA\n",
    "Kansas\t        20\tKS\n",
    "Kentucky\t    21\tKY\n",
    "Louisiana\t    22\tLA\n",
    "Maine\t        23\tME\n",
    "Maryland\t    24\tMD\n",
    "Massachusetts\t25\tMA\n",
    "Michigan\t    26\tMI\n",
    "Minnesota\t    27\tMN\n",
    "Mississippi\t    28\tMS\n",
    "Missouri\t    29\tMO\n",
    "Montana\t        30\tMT\n",
    "Nebraska\t    31\tNE\n",
    "Nevada\t        32\tNV\n",
    "New Hampshire\t33\tNH\n",
    "New Jersey\t    34\tNJ\n",
    "New Mexico\t    35\tNM\n",
    "New York\t    36\tNY\n",
    "North Carolina\t37  NC\n",
    "North Dakota\t38  ND\n",
    "Ohio\t        39  OH \n",
    "Oklahoma\t    40  OK\n",
    "Oregon\t        41  OR\n",
    "Pennsylvania\t42  PA\n",
    "Rhode Island\t44  RI\n",
    "South Carolina\t45  SC\n",
    "South Dakota\t46  SD\n",
    "Tennessee\t    47  TN\n",
    "Texas\t        48  TX\n",
    "Utah\t        49  UT\n",
    "Vermont\t        50  VT\n",
    "Virginia\t    51  VA\n",
    "Washington\t    53  WA\n",
    "West Virginia\t54  WV\n",
    "Wisconsin\t    55  WI\n",
    "Wyoming\t        56  WY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query='state:{} county:*'.format(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = c.acs5.get(var, geo = {'for': 'tract:*',\n",
    "                             'in': sql_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.append('county')\n",
    "var.append('state')\n",
    "var.append('tract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('variables_' + state + '.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the thresholds for each of the counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = df.county.unique()\n",
    "counties = {}\n",
    "counties = counties.fromkeys(county)\n",
    "for i in county:\n",
    "    counties[i] = np.median(df[df.county == i].B19013_001E)\n",
    "df_threshold = pd.DataFrame.from_dict(counties, orient='index')\n",
    "df_threshold = df_threshold.rename(columns={0:'median'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_typo['vvli_threshold']=0.3*df_typo['median']\n",
    "df_threshold['vli_threshold'] = 0.5*df_threshold['median']\n",
    "df_threshold['li_threshold'] = 0.8*df_threshold['median']\n",
    "df_threshold['mi_threshold'] = 1.2*df_threshold['median']\n",
    "df_threshold['mhi_threshold'] = 1.5*df_threshold['median']\n",
    "df_threshold['hi_threshold'] = 2*df_threshold['median']\n",
    "df_threshold['vhi_threshold'] = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the different typologies based on each county's median income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[]\n",
    "for i in county:\n",
    "    with open('variables_'+state+'.csv', 'r') as fi:\n",
    "        reader = csv.DictReader(fi)\n",
    "        def creator(reader, c):\n",
    "            bt = filter(lambda x: x['county'] == c, reader)\n",
    "            return (list(bt))\n",
    "        value = creator(reader, i)\n",
    "    values.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the migration dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2 = np.zeros((len(county),len(buckets_2)-1))\n",
    "for j in range(0, len(county)):\n",
    "    col = 1\n",
    "    for i in range(0, len(buckets_2)-1):\n",
    "        if buckets_2[i] > df_threshold.iloc[j, col]:\n",
    "            table_2[j, i] = 0\n",
    "            col = col+1\n",
    "        elif buckets_2[i+1] < df_threshold.iloc[j, col]:\n",
    "                table_2[j, i] = True\n",
    "        else:\n",
    "                table_2[j, i] = (df_threshold.iloc[j, col] - buckets_2[i]) / (buckets_2[i+1] - buckets_2[i])\n",
    "                col = col+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tract = []\n",
    "for j in range(0, len(county)):\n",
    "    for i in range(0, len(values[j])):\n",
    "        typo = []\n",
    "        summ = 0\n",
    "        for col in range(0,len(buckets_2)-1):\n",
    "            moved = float(values[j][i][var[36+col*2]])\n",
    "            if float(values[j][i][var[34]])!=0:\n",
    "                per = moved/float(values[j][i][var[34]])\n",
    "            else:\n",
    "                per = 0\n",
    "            if table_2[j, col] == 1:\n",
    "                summ = summ + per\n",
    "            elif table_2[j, col] != 0:\n",
    "                summ = summ + per*table_2[j, col]\n",
    "                typo.append(summ)\n",
    "                summ = per*(1-table_2[j, col])\n",
    "            elif ((table_2[j, col] == 0)&(float(values[j][i][var[34]])!=0)):\n",
    "                typo.append(summ)\n",
    "                col = col+1\n",
    "                summ = per * table_2[j, col] + float(values[j][i][var[36+(col-1)*2]])/float(values[j][i][var[34]]) \n",
    "        typo.append(summ)\n",
    "        census_tract.append(typo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the margin of error for the migration typologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig_moe = []\n",
    "for j in range(0, len(county)):\n",
    "    for i in range(0, len(values[j])):\n",
    "        typo = []\n",
    "        summ = 0\n",
    "        for col in range(0,len(buckets_2)-1):\n",
    "            dividend_1 = float(values[j][i][var[37+col*2]])\n",
    "            divisor_1 = float(values[j][i][var[36+col*2]])\n",
    "            dividend = float(values[j][i][var[37+(col+1)*2]])\n",
    "            divisor = float(values[j][i][var[36+(col+1)*2]])\n",
    "            dividend_2 = float(values[j][i][var[35]])\n",
    "            divisor_2 = float(values[j][i][var[34]])\n",
    "            if ((divisor != 0) & (divisor_1 != 0) & (divisor_2 != 0)):\n",
    "                error = (dividend_1/divisor_1 + dividend_2/divisor_2)*(divisor_1/divisor_2)\n",
    "                error_2 = (dividend/divisor + dividend_2/divisor_2)*(divisor/divisor_2)\n",
    "            else:\n",
    "                error = 0\n",
    "            if table_2[j, col] == 1:\n",
    "                summ = summ + error\n",
    "            elif table_2[j, col] == 0:\n",
    "                typo.append(summ)\n",
    "                col = col+1\n",
    "                summ = summ + error_2*table_2[j, col] + error*table_2[j, col-1]\n",
    "            else :\n",
    "                summ = summ + error*table_2[j, col]\n",
    "                typo.append(summ)\n",
    "                summ = (1-table_2[j, col])*error\n",
    "        typo.append(summ)\n",
    "        mig_moe.append(typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig_moe_df = pd.DataFrame(mig_moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig_moe_df = pd.DataFrame(np.nan_to_num(mig_moe_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mig = pd.DataFrame(census_tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mig = pd.DataFrame(np.nan_to_num(df_mig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mig = df_mig.rename(columns={0:'vli_mig_10', 1:'li_mig_10', 2:'mi_mig_10', 3:'mhi_mig_10', 4:'hi_mig_10', \n",
    "                                5:'vhi_mig_10'})\n",
    "mig_moe_df = mig_moe_df.rename(columns={0:'vli_mig_10_moe', 1:'li_mig_10_moe', 2:'mi_mig_10_moe', 3:'mhi_mig_10_moe',\n",
    "                                        4:'hi_mig_10_moe',5:'vhi_mig_10_moe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_mig, mig_moe_df, pd.DataFrame(df['state']), pd.DataFrame(df['county']), \n",
    "                      pd.DataFrame(df['tract'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['per_all_li_mig_10'] = df_final['vli_mig_10'] + df_final['li_mig_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_len = len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_len = len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of information lost is: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('The percentage of information lost is: {}'.format((prev_len-final_len)*100/prev_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['GEOid2'] = df_final['state'] + df_final['county'] + df_final['tract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(state + '_2010_variables.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
